import warnings
import os
import base64
import zlib
import google.generativeai as genai # type: ignore
from parser import Parser
# Suppress GRPC warnings
warnings.filterwarnings("ignore", category=RuntimeWarning)
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

"""
analyzer.py

Gets the encoded string from parser.py using Parser.zlibcomp()
Analyzes the decompressed code using Gemini API
Generates documentation
"""

def decompress_ast(compressed: str) -> str:
    """Decompress a base64+zlib compressed AST string"""
    decoded = base64.b64decode(compressed)
    decompressed = zlib.decompress(decoded)
    return Parser.unreplacek(decompressed.decode('utf-8'))

def analyze_code(compressed_ast: str) -> str:
    """Analyze code using Gemini API and generate documentation"""
    
    # Configure API
    api_key = input("Input your Gemini API key: ")
    genai.configure(api_key=api_key)

    # Configure generation parameters
    generation_config = {
        "temperature": 0,
        "top_p": 0.95,
        "top_k": 64,
        "max_output_tokens": 8192,
    }

    # Initialize model
    model = genai.GenerativeModel(
        model_name="gemini-pro",
        generation_config=generation_config # type: ignore
    )


    # System prompt
    SYSTEM_PROMPT = """You are an expert Python documentation writer with deep knowledge of code analysis and AST interpretation. 
You will be provided with a string of encoded text. Here is the code that you can use to decode it:
```
import base64, zlib, ast
def unreplacek(s):
    i={'FV':'FormattedValue','FD':'FunctionDef','EX':'ExceptHandler','IF':'ImportFrom','AA':'AnnAssign','ATT':'Attribute','ARG':'arguments','SS':'Subscript','CO':'Constant','CD':'ClassDef','UO':'UnaryOp','K':'keyword','ST':'Starred','R':'Return','AS':'Assign','I':'Import','M':'Module','AL':'alias','S':'Store','val':'value','C':'Call','E':'Expr','N':'Name','L':'Load'}
    for l,x in i.items():s=s.replace(l,x)
    return s
a = ast.unparse(ast.parse(unreplacek(zlib.decompress(base64.b64decode(comp)).decode('utf-8'))))
```
The decoded string will be an Abstract Syntax Tree (AST) generated by python's ast module. 
Your task is to analyze the decoded AST, and generate comprehensive, professional documentation.
Structure your documentation following these specific sections:
For the project overview: main purpose and functionality of the code, high-level architecture/design patterns used, key features
For the technical documentation:
For each class: name and inheritance, purpose, attributes and their types. Methods should be documented like functions. 
For each function: purpose, parameters and their types, return values and types, examples with expected outputs, any exceptions raised. 
Dependencies: Required external packages, Version requirements, System requirements
Implementation Details: Key algorithms explained, Important design decisions, Performance considerations, Threading/async behavior (if any)
Usage Guide: Installation instructions, Configuration requirements, Code examples for common use cases, Best practices
Notes and Warnings: Known limitations, Common pitfalls, Security considerations (if applicable)

Format the documentation in clean, well-structured markdown with appropriate headers, code blocks, and lists. Use ```python for code examples.
Leave out any unnecessary headers. Format the code such that it is simple and easy to read. 
Based on the AST structure, infer and document any implicit behaviors or patterns. If certain aspects cannot be determined from the AST alone, note this in the documentation.
Here is the encoded text you will be working on:"""

    # Start chat and send decompressed AST
    chat = model.start_chat(history=[])
    decompressed = decompress_ast(compressed_ast)
    
    # Count tokens in the prompt
    prompt = f"{SYSTEM_PROMPT}\n\nCode AST:\n{decompressed}"
    prompt_tokens = model.count_tokens(prompt).total_tokens
    
    # Send message and get response
    response = chat.send_message(prompt)
    
    # Count tokens in the response
    response_tokens = model.count_tokens(response.text).total_tokens
    
    # Print token usage
    print("\nToken Usage:")
    print(f"Prompt tokens: {prompt_tokens}")
    print(f"Response tokens: {response_tokens}")
    print(f"Total tokens: {prompt_tokens + response_tokens}")
    
    return response.text

def main(compressed_ast):
    '''entry point'''
    # Generate documentation
    documentation = analyze_code(compressed_ast)
    
    # Save to file
    with open("documentation.md", "w") as f:
        f.write(documentation)
    
    print("Documentation generated and saved to documentation.md")

if __name__ == "__main__":
    p = Parser("main.py")
    compressed_ast = p.parse()
    main(compressed_ast)